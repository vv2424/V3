<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Here is the demo page. | V3 INPAINTING</title>
<meta name="generator" content="Jekyll v3.7.4" />
<meta property="og:title" content="Here, you will find demos of our paper." />
<meta property="og:locale" content="en_US" />
<meta name="description" content="FLEXIBLE MUSIC INPAINTING VIA MASKING MIXED-LEVEL REPRESENTATIONS" />
<meta property="og:description" content="FLEXIBLE MUSIC INPAINTING VIA MASKING MIXED-LEVEL REPRESENTATIONS" />
<link rel="canonical" href="https://github.com/vv2424/V3/" />
<meta property="og:url" content="https://vv2424.github.io/V3/" />
<meta property="og:site_name" content="Inpainting model" />
<script type="application/ld+json">
{"headline":"Here, you will find demos of our paper.","@type":"WebSite","url":"https://vv2424.github.io/V3/","name":"V3","description":"FLEXIBLE MUSIC INPAINTING VIA MASKING MIXED-LEVEL REPRESENTATIONS","@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <link rel="stylesheet" href="/GAN-WN/assets/css/style.css?v=a4406d7743520b1da760cd557398952e97f3d1e3">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">V3-INPAINTING</h1>
      <h2 class="project-tagline">FLEXIBLE MUSIC INPAINTING VIA MASKING MIXED-LEVEL REPRESENTATIONS</h2>
      
        <a href="https://github.com/vv2424/V3/" class="btn">View on GitHub</a>
      
      
    </section>

    <section class="main-content">
      <h2 id="here-you-will-find-demos-of-our-paper">Here, you will find demos of our paper.</h2>
      
<p>Our model consists of two components: 1) a mixed-level encoder-decoder module to learn mixed-level represenation and 2) an auto-regressive decoder to inpaint missing notes using mixed-level representations.
<img src="modeljie.png" alt="Pipelines" /></p>

<p>In our paper,we elaborate on how the proposed model inpaints:</p>

<ol>
  <li>
    <p>Variable-position inpainting.</p>
  </li>
  <li>
    <p>Variable-length inpainting.</p>
  </li>
  <li>
    <p>Irregularly-corrupted context attending.</p>
  </li>
  <li>
    <p>Mixed-level representation sampling.</p>
  </li>
  <li>
    <p>Controllable generation in number of notes in one measure.</p>
  </li>
</ol>




<p>We show some demos in the inference section.</p>

<h3 id="1-Variable-position inpainting">1. Variable-position inpainting</h3>
<p>An example of a 16-bar melody missing 1-4th, 5-8th, 9-12th or 13-16th bars.</p>
<p>Missing 1-4th bars.</p>
<audio controls=""> <source src="./songs/inpaint-variable-position/19_34gphrase1_bip.wav" type="audio/wav" /></audio>
<p>Missing 5-8thth bars.</p>
<audio controls=""> <source src="./songs/inpaint-variable-position/19_34phrase2_bip.wav" type="audio/wav" /></audio>
<p>Missing 9-12th bars.</p>
<audio controls=""> <source src="./songs/inpaint-variable-position/19_34phrase3_bip.wav" type="audio/wav" /></audio>
<p>Missing 12-16th bars.</p>
<audio controls=""> <source src="./songs/inpaint-variable-position/19_34phrase4_bip.wav" type="audio/wav" /></audio>
      
      
      
<p>Following the top pipeline from the above figure, our process looks for frequencies specific to the violin, and attempts to silence the piano.</p>
<audio controls=""> <source src="https://raw.githubusercontent.com/SvenShade/Thesis_Demo/master/source_sep_violin.wav" type="audio/wav" /></audio>
<p>Another example from the same piece.</p>
<audio controls=""> <source src="https://raw.githubusercontent.com/SvenShade/Thesis_Demo/master/SS-ref.wav" type="audio/wav" /></audio>
<p>Now, our CNN baseline has a go at isolating the violin.</p>
<audio controls=""> <source src="https://raw.githubusercontent.com/SvenShade/Thesis_Demo/master/SS-CNN.wav" type="audio/wav" /></audio>
<p>The result from our method. It introduces a different sort of artefact, losing high-frequency fidelity primarily due to the lossy spectrogram reconstruction process. Yet, notice the piano source is much better attenuated.</p>
<audio controls=""> <source src="https://raw.githubusercontent.com/SvenShade/Thesis_Demo/master/SS-cGAN-Secx2.wav" type="audio/wav" /></audio>

<p>Below, we give a closer look at source-separation, with a ground-truth difference overlay. Alignments with ground truth are cyan. Areas where ground truth is missed are red. Interference (piano) is white. Observe cGAN’s precision in removing interference, sometimes at the cost of detail.
<img src="https://raw.githubusercontent.com/SvenShade/Thesis_Demo/master/overlay.jpg" alt="Pipelines" /></p>

<h3 id="2-super-resolution-as-spectral-inpainting">2. Super-resolution as Spectral Inpainting</h3>
<p>We start with a violin phrase by Paganini, at a sample rate of 4kHz (ultra low-fidelity).</p>
<audio controls=""> <source src="https://raw.githubusercontent.com/SvenShade/Thesis_Demo/master/paganini_lofi.wav" type="audio/wav" /></audio>
<p>Here’s the result of our method.</p>
<audio controls=""> <source src="https://raw.githubusercontent.com/SvenShade/Thesis_Demo/master/paganini_bandavg-plus-logcont.wav" type="audio/wav" /></audio>
<p>This is the ground truth.</p>
<audio controls=""> <source src="https://raw.githubusercontent.com/SvenShade/Thesis_Demo/master/paganini_truth.wav" type="audio/wav" /></audio>
<p>Another example. This time, from Chopin. Here is the lofi clip:</p>
<audio controls=""> <source src="https://raw.githubusercontent.com/SvenShade/Thesis_Demo/master/chopin-lofi-clip.mp3" type="audio/mp3" /></audio>
<p>Here is the baseline performance (linear interpolation):</p>
<audio controls=""> <source src="https://raw.githubusercontent.com/SvenShade/Thesis_Demo/master/chopin-lin-clip.mp3" type="audio/mp3" /></audio>
<p>Here is the result of our cGAN process.</p>
<audio controls=""> <source src="https://raw.githubusercontent.com/SvenShade/Thesis_Demo/master/chopin-LC-clip.mp3" type="audio/mp3" /></audio>
<p>Ground truth.</p>
<audio controls=""> <source src="https://raw.githubusercontent.com/SvenShade/Thesis_Demo/master/chopin-gt-clip.mp3" type="audio/mp3" /></audio>

<p>Alternatively, we can use a Wavenet to reconstruct the raw audio directly from the Mel-spectrogram (see the lower pipeline in the figure from before). This kind of modelling proved to be highly resource intensive, with training taking over a fortnight to see convergence on our NVIDIA GTX1080ti. Despite lacking the memory necessary to train a sufficiently complex model, the concept is there.</p>
<audio controls=""> <source src="https://raw.githubusercontent.com/SvenShade/Thesis_Demo/master/paganini_WN_guidefactor30.wav" type="audio/wav" /></audio>
<p>We can further improve the output of our unstable Wavenet. Instead of conditioning Wavenet on the spectrogram alone, we also feed in the timesteps of the original, lofi audio. At every step, we now take the average of both original audio and Wavenet’s prediction (weighted towards the former). This can be thought of as a sort of teacher-forcing generation. As usual, that timestep becomes part of the series, and in turn influences future predictions. Here, we apply this to our Chopin clip.</p>
<audio controls=""> <source src="https://raw.githubusercontent.com/SvenShade/Thesis_Demo/master/lofi-WN-20-iter1.wav" type="audio/wav" /></audio>

<h3 id="3-synthesis-as-style-transfer-onto-harmonics">3. Synthesis as Style Transfer Onto Harmonics</h3>

<p>Here is the melody from the folk song, ‘Scarborough Fair’, as played by a sinewave generator.
These sinewaves include the fundamental as well as the first few harmonics, in order to provide structure for cGAN to translate.</p>
<audio controls=""> <source src="https://raw.githubusercontent.com/SvenShade/Thesis_Demo/master/scarborough_H2R_harmonics.wav" type="audio/wav" /></audio>
<p>Here is the same harmonic track, with the violin ‘style’ applied:</p>
<audio controls=""> <source src="https://raw.githubusercontent.com/SvenShade/Thesis_Demo/master/scarborough_H2R_enhance_linreconst_logcontr.wav" type="audio/wav" /></audio>

<p>Finally, we leave the reader with the first 7 notes of the chorus of Rick Astley’s “Never Gonna Give You Up”, as played by a sinewave generator.</p>
<audio controls=""> <source src="https://raw.githubusercontent.com/SvenShade/Thesis_Demo/master/rick_harmonics.wav" type="audio/wav" /></audio>
<p>Here is the result of our method, applying violin stylisation :)</p>
<audio controls=""> <source src="https://raw.githubusercontent.com/SvenShade/Thesis_Demo/master/rick_synth.wav" type="audio/wav" /></audio>


      <footer class="site-footer">
        
          <span class="site-footer-owner"><a href="https://github.com/SvenShade/GAN-WN">GAN-WN</a> is maintained by <a href="https://github.com/SvenShade">SvenShade</a>.</span>
        
        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.</span>
      </footer>
    </section>

    
  </body>
</html>
